{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dcgan_MNIST_3.ipynb","provenance":[{"file_id":"1kZcQHnDs82mcYJDTO_vZvu1OVImBV0NF","timestamp":1585682688698},{"file_id":"1MqK-jiDAHVtfG2CyLpiIEbWJtv1PyDtp","timestamp":1585426437412},{"file_id":"1noUPjQgc1lOvl-hz_jrLQx9d7egQu18T","timestamp":1585005078107}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"RO0PoQ1TUHgg","colab_type":"code","colab":{}},"source":["# This code was developed using ideas from the following sources:\n","\n","# DCGAN Adventures with Cifar10 by Stepan Ulyanin\n","# Deep Convolutional Generative Adversarial Network Tensorflow Tutorial\n","# How to Develop a GAN to Generate CIFAR10 Small Color Photographs by Jason Brownlee\n","# Having Fun with Deep Convolutional GANs by Naoki Shibuya"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d1P_LRa-lDSq","colab_type":"code","colab":{}},"source":["# Import necessary libraries\n","# Neural net will be constructed using tensorflow.keras\n","\n","from __future__ import absolute_import, division, print_function, unicode_literals\n","import tensorflow as tf\n","\n","import numpy as np\n","from tensorflow import keras\n","# from tensorflow.keras import layers\n","from matplotlib import pyplot\n","import tensorflow_datasets as tfds"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gDXM-qsLlXYc","colab_type":"code","colab":{}},"source":["# Some helper functions for manipulating MNIST data\n","\n","# select random real samples to be classified by discriminator\n","def real_samples(data,n_samples):\n","  # data is the CIFAR10 dataset\n","  # take random elements from the dataset\n","  x = np.random.randint(0,data.shape[0],n_samples)\n","  X = data[x] #this is the corresponding image\n","  y = np.ones((n_samples,1)) # this classifies the X value as a real image\n","  return X , y\n","\n","# given fake points in latent space, generate some fake images to give to discriminator\n","def make_fake_samples(generator,lat_dim,n_samples):\n","  x_in = np.random.randn(n_samples,lat_dim)\n","  # given the input, the generator model uses the Keras function 'predict' to \\\\\n","  #   produce outputs (like our FeedForward technique from class)\n","  X = generator.predict(x_in)\n","  # we label these outputs as fake, for classifying with the discriminator\n","  y = np.zeros((n_samples,1))\n","  return X , y\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kvSRUYnPqEJB","colab_type":"code","colab":{}},"source":["# Some more functions for displaying and measuring the network\n","\n","# save a plot of fake images after a certain number of epochs\n","def save_plot(images,epoch,n=5):\n","  # scale images to an appropriate range for imshow:\n","  images = (images*127.5)+127.5\n","  images = images.reshape(images.shape[0],28,28)\n","\n","  for i in range(n**2):\n","    pyplot.subplot(n,n,i+1); pyplot.axis('off')\n","    pyplot.imshow(images[i],cmap='gray')\n","  \n","  #save the images\n","  file1 = 'plot_fakes_epoch{}.png'.format(epoch+1)\n","  pyplot.savefig(file1)\n","  pyplot.close()\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"snUh9yInqT4R","colab_type":"code","colab":{}},"source":["# construct the generator, discriminator, and the full neural net by combining them\n","\n","# First the discriminator model, which takes in a 32x32x3 image.\n","#  We use Conv2D to build layers. We can construct Conv2D in a way such that it\n","#  Reduces the x,y dimensions of the previous layer by half. The parameters \n","#  'kernel', 'strides' and 'padding will change the size of the next layer. Literature\n","#  recommends using kernel = (3,3) for this problem.\n","#  Example: given an input layer with dimensions (64,64,128).\n","#           Conv2D(256,(3,3), strides = (2,2)) will give dimensions (62,62,256)\n","#           Conv2D(128,(3,3), strides = (2,2),padding = 'same') \n","#                                      will give dimensions (32,32,128)\n","\n","def build_discriminator(shape_in = (28,28,1)):\n","  disc_model = keras.Sequential()\n","  \n","  disc_model.add(keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',input_shape=shape_in))\n","\n","  disc_model.add(keras.layers.LeakyReLU())\n","  disc_model.add(keras.layers.Dropout(0.3))\n","\n","  disc_model.add(keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n","  disc_model.add(keras.layers.LeakyReLU())\n","  disc_model.add(keras.layers.Dropout(0.3))\n","  \n","  disc_model.add(keras.layers.Flatten())\n","  disc_model.add(keras.layers.Dense(1))\n","  \n","  #opt = keras.optimizers.Adam(1e-4)\n","  #disc_model.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy'])\n","\n","  return disc_model\n","\n","# next the generator model\n","# Here we use Conv2DTranspose, and instead of downsampling the dimension of our\n","#  layers, it upsamples. so we can instead go from (4,4,256) to (8,8,128). The\n","#  parameters are largely the same otherwise.\n","def build_generator(lat_dim):\n","  # lat_dim is the dimension of the latent space (usually lat_dim=100)\n","  gen_model = keras.Sequential()\n","\n","  gen_model.add(keras.layers.Dense(7*7*256, use_bias=False, input_dim=lat_dim))\n","  gen_model.add(keras.layers.BatchNormalization())\n","  gen_model.add(keras.layers.LeakyReLU())\n","\n","  gen_model.add(keras.layers.Reshape((7, 7, 256)))\n","\n","  gen_model.add(keras.layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n","  gen_model.add(keras.layers.BatchNormalization())\n","  gen_model.add(keras.layers.LeakyReLU())\n","\n","  gen_model.add(keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n","  gen_model.add(keras.layers.BatchNormalization())\n","  gen_model.add(keras.layers.LeakyReLU())\n","\n","  gen_model.add(keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n","  \n","  #opt = keras.optimizers.Adam(lr=0.0004)\n","  #gen_model.compile(loss='binary_crossentropy',optimizer=opt)\n","\n","  return gen_model\n","\n","# now we put them together\n","def build_dcgan(gen_model,disc_model):\n","  # don't train weights in discriminator\n","  #disc_model2 = tf.keras.models.clone_model(disc_model)\n","  disc_model.trainable = False\n","\n","  gan_model = keras.Sequential()\n","\n","  gan_model.add(gen_model)\n","  gan_model.add(disc_model)\n","\n","  opt = keras.optimizers.Adam(lr=0.0004) #try lr = 0.0002 or 0.001\n","  gan_model.compile(loss='binary_crossentropy',optimizer=opt)\n","\n","  return gan_model\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CYwz-GOX_ha-","colab_type":"code","colab":{}},"source":["cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","\n","def discriminator_loss(real_output, fake_output):\n","    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n","    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n","    total_loss = real_loss + fake_loss\n","    return total_loss\n","\n","def generator_loss(fake_output):\n","    return cross_entropy(tf.ones_like(fake_output), fake_output)\n","\n","generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n","discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MOmhj7TDwiS6","colab_type":"code","colab":{}},"source":["# now we can train our gan model\n","\n","def train(generator,discriminator,data,lat_dim,epochs=50):\n","\n","  for i in range(epochs):\n","    for images in data:\n","      noise = tf.random.normal([images.shape[0],lat_dim])\n","\n","      with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","        \n","        generated_images = generator(noise,training=True)\n","        real_output = discriminator(images, training=True)\n","        fake_output = discriminator(generated_images, training=True)\n","\n","        gen_loss = generator_loss(fake_output)\n","        disc_loss = discriminator_loss(real_output,fake_output)\n","\n","      gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n","      gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n","\n","      generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n","      discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n","\n","    print('epoch = {}, Loss = {}'.format(i+1,disc_loss))\n","    if (i+1) % 2 == 0:\n","      n = 5\n","      latent_points = tf.random.normal([n**2,lat_dim])\n","      X = (generator.predict(latent_points)) #*127.5)+127.5\n","      X = X.reshape(N,28,28)    \n","      save_plot(X,epoch,n)\n","\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pEiBBk6kp93j","colab_type":"code","outputId":"77e91608-0bf6-48e6-9f13-f695feb928e8","executionInfo":{"status":"ok","timestamp":1587261208382,"user_tz":240,"elapsed":8514,"user":{"displayName":"Dongni Xie","photoUrl":"","userId":"09642087591972648837"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# load the data in from keras.datasets\n","(data,_),(_,_) = keras.datasets.mnist.load_data()\n","# Each element of data has dimension 32x32x3\n","# Convert data to from ints to floats\n","data = data.astype('float32')\n","# Map image data from [0,255] to [-1,1]\n","data = (data-127.5) / 127.5\n","data = data.reshape(data.shape[0],28,28,1)\n","train_data = tf.data.Dataset.from_tensor_slices(data).shuffle(data.shape[0]).batch(256)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I3JfOK5G8r-P","colab_type":"code","colab":{}},"source":["# now we will build our model:\n","lat_dim = 100\n","disc_model = build_discriminator()\n","gen_model = build_generator(lat_dim)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pgYB8NlpbF0L","colab_type":"code","outputId":"5c619726-db13-4754-f366-9fa11a2dbc4a","executionInfo":{"status":"error","timestamp":1587261690818,"user_tz":240,"elapsed":51559,"user":{"displayName":"Dongni Xie","photoUrl":"","userId":"09642087591972648837"}},"colab":{"base_uri":"https://localhost:8080/","height":317}},"source":["#train(gen_model,disc_model,gan_model,data,lat_dim,epochs=60)\n","train(gen_model,disc_model,train_data,lat_dim,epochs=3)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["epoch = 1, Loss = 1.249799370765686\n","epoch = 2, Loss = 0.7263081669807434\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-b21ffc245dab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisc_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlat_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-c56c9d006fcd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(generator, discriminator, data, lat_dim, epochs)\u001b[0m\n\u001b[1;32m     44\u001b[0m       \u001b[0mlatent_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlat_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#*127.5)+127.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m       \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m       \u001b[0msave_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m#  percent_correct(i,generator,discriminator,data,lat_dim,n_samples=100)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'N' is not defined"]}]},{"cell_type":"code","metadata":{"id":"i52sSh-Ten-7","colab_type":"code","outputId":"ffd403c8-a332-4d7a-e1c5-6a57510412e0","executionInfo":{"status":"error","timestamp":1585771615139,"user_tz":240,"elapsed":733,"user":{"displayName":"brad hedges","photoUrl":"","userId":"02896313396305335471"}},"colab":{"base_uri":"https://localhost:8080/","height":368}},"source":["percent_correct(10,gen_model,disc_model,data,lat_dim,n_samples=100)\n","\n","# Uncomment to save the model\n","\n","#gen_model.compile()\n","#gen_model.save('generator_mnist.h5')\n","\n","# Recreate the exact same model purely from the file\n","new_model = keras.models.load_model('generator100e.h5')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["4/4 [==============================] - 0s 2ms/step - loss: 0.0000e+00\n"],"name":"stdout"},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-86-6ff9553b486e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpercent_correct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgen_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisc_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlat_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Uncomment to save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#gen_model.compile()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-85-ea7e9077f43f>\u001b[0m in \u001b[0;36mpercent_correct\u001b[0;34m(epoch, generator, discriminator, data, lat_dim, n_samples)\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mX_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;31m# Check how good the discriminator is at identifying true samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0mX_false\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_false\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fake_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlat_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable"]}]},{"cell_type":"code","metadata":{"id":"uz7h7U9aIoa7","colab_type":"code","outputId":"5e8d99e8-d8b6-4bb3-a0ef-dc50bfa8f1e5","executionInfo":{"status":"ok","timestamp":1585771056508,"user_tz":240,"elapsed":318,"user":{"displayName":"brad hedges","photoUrl":"","userId":"02896313396305335471"}},"colab":{"base_uri":"https://localhost:8080/","height":935}},"source":["gen_model.summary()\n","disc_model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_20\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_15 (Dense)             (None, 12544)             1254400   \n","_________________________________________________________________\n","batch_normalization_21 (Batc (None, 12544)             50176     \n","_________________________________________________________________\n","leaky_re_lu_37 (LeakyReLU)   (None, 12544)             0         \n","_________________________________________________________________\n","reshape_7 (Reshape)          (None, 7, 7, 256)         0         \n","_________________________________________________________________\n","conv2d_transpose_21 (Conv2DT (None, 7, 7, 128)         819200    \n","_________________________________________________________________\n","batch_normalization_22 (Batc (None, 7, 7, 128)         512       \n","_________________________________________________________________\n","leaky_re_lu_38 (LeakyReLU)   (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","conv2d_transpose_22 (Conv2DT (None, 14, 14, 64)        204800    \n","_________________________________________________________________\n","batch_normalization_23 (Batc (None, 14, 14, 64)        256       \n","_________________________________________________________________\n","leaky_re_lu_39 (LeakyReLU)   (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","conv2d_transpose_23 (Conv2DT (None, 28, 28, 1)         1600      \n","=================================================================\n","Total params: 2,330,944\n","Trainable params: 2,305,472\n","Non-trainable params: 25,472\n","_________________________________________________________________\n","Model: \"sequential_19\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_14 (Conv2D)           (None, 14, 14, 64)        1664      \n","_________________________________________________________________\n","leaky_re_lu_35 (LeakyReLU)   (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","dropout_14 (Dropout)         (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","conv2d_15 (Conv2D)           (None, 7, 7, 128)         204928    \n","_________________________________________________________________\n","leaky_re_lu_36 (LeakyReLU)   (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","dropout_15 (Dropout)         (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","flatten_7 (Flatten)          (None, 6272)              0         \n","_________________________________________________________________\n","dense_14 (Dense)             (None, 1)                 6273      \n","=================================================================\n","Total params: 212,865\n","Trainable params: 212,865\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4ScSC1B0OrQR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YbBURZ4fQTX7","colab_type":"code","colab":{}},"source":["N = 5\n","epoch = 50\n","\n","latent_points = tf.random.normal([N,100])\n","\n","X = (gen_model.predict(latent_points)) #*127.5)+127.5\n","X = X.reshape(N,28,28)\n","\n","pyplot.figure(figsize = (11,11))\n","for i in range(N):\n","  pyplot.subplot(1,N,i+1);\n","  pyplot.axis('off')\n","  pyplot.imshow(X[i, :, :],cmap = 'gray');\n","file1 = 'plot_fakes_epoch{}.png'.format(epoch+1)\n","pyplot.savefig(file1)\n","pyplot.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CNCZ6taJQXt3","colab_type":"code","colab":{}},"source":["latent_points = tf.random.normal([3000,100])\n","\n","X = (gen_model.predict(latent_points)) #*127.5)+127.5\n","X = X.reshape(3000,28,28)\n","\n","np.save('MNIST_fake_images',X)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wzz0P36ZY1ro","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}
